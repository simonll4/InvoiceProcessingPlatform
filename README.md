# ğŸ“„ Invoice Processing Platform

> **Plataforma unificada de procesamiento inteligente de facturas con OCR, LLM y asistente conversacional**

---

## ğŸ¯ DescripciÃ³n

Sistema empresarial completo para automatizar el procesamiento y anÃ¡lisis de facturas mediante:

- **ğŸ”„ Pipeline OCR/LLM**: ExtracciÃ³n automÃ¡tica de datos estructurados de facturas
- **ğŸ’¬ Asistente Conversacional**: Q&A en lenguaje natural sobre facturas procesadas
- **ğŸ¨ Interfaz Web Unificada**: UI moderna con tabs para ambas funcionalidades

## âœ¨ CaracterÃ­sticas Principales

### Pipeline de Procesamiento
- âœ… Soporte multi-formato: PDF, JPG, PNG, BMP
- âœ… OCR con Tesseract (inglÃ©s y espaÃ±ol)
- âœ… ExtracciÃ³n con Groq LLM (llama-3.1-8b-instant) para mÃ¡xima precisiÃ³n
- âœ… Almacenamiento estructurado en SQLite
- âœ… Procesamiento concurrente controlado

### Asistente Conversacional
- âœ… Preguntas en lenguaje natural
- âœ… MCP (Model Context Protocol) para consultas SQL seguras
- âœ… Tool calling automÃ¡tico
- âœ… Sesiones con historial de conversaciÃ³n
- âœ… Respuestas contextualizadas en espaÃ±ol

## ğŸ—ï¸ Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Frontend (SPA con Tabs)           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Pipeline   â”‚  â”‚   Assistant     â”‚  â”‚
â”‚  â”‚    Tab      â”‚  â”‚      Tab        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚ HTTP/REST
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Unified API (FastAPI)                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Routers (Modular)               â”‚   â”‚
â”‚  â”‚  â€¢ /api/pipeline/extract         â”‚   â”‚
â”‚  â”‚  â€¢ /api/assistant/chat           â”‚   â”‚
â”‚  â”‚  â€¢ /api/health                   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Pipeline  â”‚  â”‚   Assistant      â”‚   â”‚
â”‚  â”‚  Module   â”‚  â”‚    Module        â”‚   â”‚
â”‚  â”‚           â”‚  â”‚  â€¢ Orchestrator  â”‚   â”‚
â”‚  â”‚  â€¢ OCR    â”‚  â”‚  â€¢ MCP Server    â”‚   â”‚
â”‚  â”‚  â€¢ LLM    â”‚  â”‚  â€¢ Sessions      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚   SQLite    â”‚
      â”‚   app.db    â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisitos

- Docker Desktop / Docker Engine (24+)
- (Opcional) Drivers NVIDIA + `nvidia-container-toolkit` si quieres probar la GPU MX130 (Maxwell)

### 1. Configurar entorno

```bash
cp configs/env/.env.example configs/env/.env
# Define PIPELINE_LLM_API_KEY y/o LLM_API_KEY con tu token de Groq
# Ajusta PIPELINE_LLM_MODEL o LLM_MODEL si quieres otro modelo hospedado en Groq
```

### 2. Levantar el servicio

```bash
docker compose up -d
```

### 3. Acceder a la plataforma

```
http://localhost:7000
```

### 4. (Opcional) Ajustar lÃ­mites de Groq

- Sube `RATE_LIMIT_RPM` o `RATE_LIMIT_TPM` solo si tu plan de Groq lo permite.
- Si recibes errores de rate limit, reduce la concurrencia (`MAX_CONCURRENCY`) o aumenta los intervalos entre peticiones.

## ğŸ“š Uso

### Tab 1: Procesar Facturas

1. Arrastra una factura (PDF/imagen) al Ã¡rea de carga
2. Espera el procesamiento (OCR + LLM)
3. Visualiza los datos extraÃ­dos:
   - Vendor
   - Fecha
   - Total
   - Items

### Tab 2: Asistente Conversacional

**Preguntas sugeridas**:
```
Â¿CuÃ¡ntas facturas hay en total?
Â¿CuÃ¡l es el monto total de todas las facturas?
Â¿CuÃ¡les son los principales proveedores?
MuÃ©strame las facturas mÃ¡s recientes
Â¿CuÃ¡nto gastamos con el proveedor X en enero?
```

## ğŸ”Œ API REST

### Pipeline

```http
POST /api/pipeline/extract
Content-Type: multipart/form-data

file: <invoice.pdf>
```

**Respuesta**:
```json
{
  "vendor": "Acme Corp",
  "date": "2024-01-15",
  "total_cents": 150000,
  "currency": "USD",
  "items": [
    {
      "description": "Product A",
      "quantity": 2,
      "price_cents": 50000
    }
  ]
}
```

### Assistant

#### Chat Stateless
```http
POST /api/assistant/chat
Content-Type: application/json

{
  "question": "Â¿CuÃ¡ntas facturas hay?"
}
```

**Respuesta**:
```json
{
  "success": true,
  "answer": "Hay 25 facturas en total.",
  "session_id": null
}
```

#### Chat con SesiÃ³n
```http
# 1. Crear sesiÃ³n
POST /api/assistant/sessions
{
  "user_id": "user123"
}

# 2. Chat en sesiÃ³n
POST /api/assistant/sessions/{session_id}/chat
{
  "question": "Â¿CuÃ¡les son los principales proveedores?"
}

# 3. Obtener info de sesiÃ³n
GET /api/assistant/sessions/{session_id}
```

#### Otros endpoints
```http
GET /api/assistant/sessions     # Listar sesiones activas
GET /api/assistant/stats         # EstadÃ­sticas del asistente
GET /api/health                  # Health check
```

## ğŸ›¡ï¸ Seguridad MCP

El MCP implementa seguridad a nivel de queries:

- âœ… **Solo lectura**: SELECT, PRAGMA, EXPLAIN
- âŒ **Bloqueados**: INSERT, UPDATE, DELETE, DROP, CREATE
- ğŸ” **ValidaciÃ³n**: Todas las queries son validadas
- ğŸ“ **Logging**: Operaciones registradas

## ğŸ¨ Estructura del Proyecto

```
pipeline-python/
â”œâ”€â”€ src/                         # CÃ³digo fuente
â”‚   â”œâ”€â”€ main.py                  # FastAPI principal
â”‚   â”œâ”€â”€ routers/                 # Endpoints modulares
â”‚   â”‚   â”œâ”€â”€ pipeline.py
â”‚   â”‚   â”œâ”€â”€ assistant.py
â”‚   â”‚   â””â”€â”€ health.py
â”‚   â”œâ”€â”€ modules/                 # LÃ³gica de negocio
â”‚   â”‚   â”œâ”€â”€ pipeline/            # Pipeline OCR/LLM
â”‚   â”‚   â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”‚   â”œâ”€â”€ extract/
â”‚   â”‚   â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”‚   â”œâ”€â”€ service/
â”‚   â”‚   â”‚   â””â”€â”€ storage/
â”‚   â”‚   â””â”€â”€ assistant/           # Asistente conversacional
â”‚   â”‚       â”œâ”€â”€ orchestrator.py
â”‚   â”‚       â”œâ”€â”€ mcp_server.py
â”‚   â”‚       â”œâ”€â”€ session_manager.py
â”‚   â”‚       â”œâ”€â”€ models.py
â”‚   â”‚       â””â”€â”€ config.py
â”‚   â””â”€â”€ static/
â”‚       â””â”€â”€ index.html           # Frontend SPA
â”œâ”€â”€ configs/                     # Configuraciones
â”‚   â””â”€â”€ env/.env
â”œâ”€â”€ data/                        # Persistencia
â”‚   â”œâ”€â”€ app.db
â”‚   â”œâ”€â”€ uploads/
â”‚   â””â”€â”€ processed/
â”œâ”€â”€ datasets/                    # Datos de prueba
â”œâ”€â”€ Dockerfile
â””â”€â”€ docker-compose.yml
```

## ğŸ“Š Performance

- **Pipeline**: ~3-5 segundos por factura
- **Assistant**: ~1 segundo por pregunta
- **Concurrencia**: Configurable (default: 1)
- **Base de datos**: SQLite (file-based)

## ğŸ”§ ConfiguraciÃ³n Avanzada

### Variables de Entorno

```bash
# Pipeline
MAX_CONCURRENCY=2                    # Procesos paralelos
PDF_OCR_DPI=300                      # Calidad OCR
PDF_OCR_MAX_PAGES=5                  # PÃ¡ginas a procesar

# Pipeline LLM (Groq)
PIPELINE_LLM_PROVIDER=groq
PIPELINE_LLM_MODEL=llama-3.1-8b-instant
PIPELINE_LLM_API_BASE=https://api.groq.com/openai/v1
PIPELINE_LLM_API_KEY=tu_clave_groq
PIPELINE_LLM_ALLOW_STUB=false

# Assistant LLM (Groq)
LLM_API_BASE=https://api.groq.com/openai/v1
LLM_MODEL=llama-3.1-8b-instant
LLM_API_KEY=${GROQ_API_KEY:-}

# Rate limits Groq (free tier seguros)
RATE_LIMIT_RPM=24
RATE_LIMIT_RPD=11500
RATE_LIMIT_TPM=4800
RATE_LIMIT_TPD=400000

# Assistant
MAX_HISTORY_MESSAGES=10              # Mensajes en historial
SESSION_TIMEOUT_SECONDS=1800         # Timeout de sesiones (30min)
ENABLE_DEBUG_MODE=false              # Modo debug
# LLM_REQUEST_TIMEOUT=180            # Timeout en segundos para llamadas del assistant
```

### Cambiar modelos LLM

`configs/env/.env` expone dos bloques:

```bash
# Pipeline (Groq)
PIPELINE_LLM_MODEL=llama-3.1-8b-instant
# TambiÃ©n puedes usar mixtral-8x7b-32768, gemma2-9b-it, etc.

# Assistant (Groq)
# LLM_MODEL=llama-3.1-8b-instant   # default balanceado
# LLM_MODEL=mixtral-8x7b-32768     # mayor contexto (puede ser mÃ¡s costoso)
# LLM_MODEL=gemma2-9b-it           # alternativa conversacional
```

Modelos sugeridos:
- Pipeline: `llama-3.1-8b-instant` (Groq, buen balance velocidad/calidad)
- Assistant: `llama-3.1-8b-instant` (Groq, respuesta consistente), `mixtral-8x7b-32768` (mÃ¡s contexto), `gemma2-9b-it` (tono mÃ¡s conversacional)

## ğŸ§ª Testing

```bash
# Health check
curl http://localhost:7000/api/health

# Procesar factura
curl -X POST http://localhost:7000/api/pipeline/extract \
  -F "file=@invoice.pdf"

# Chat
curl -X POST http://localhost:7000/api/assistant/chat \
  -H "Content-Type: application/json" \
  -d '{"question": "Â¿CuÃ¡ntas facturas hay?"}'
```

## ğŸ§  MCP Oficial

El servidor MCP se implementÃ³ con el SDK oficial (`mcp.server.fastmcp`) y queda montado en el mismo proceso FastAPI:

- **Transport HTTP**: `http://localhost:7000/mcp` (compatibilidad Streamable HTTP).
- **Herramientas expuestas**: `execute_sql_query`, `get_invoice_by_id`, `search_invoices_by_vendor`, `get_top_vendors`, `search_by_text`, `get_invoices_by_date_range`, `get_database_schema`.
- **Uso**: cualquier cliente MCP (por ejemplo `mcp-cli` o integraciones editoriales) puede conectarse a esa URL y consumir la base SQLite en modo solo lectura.

> Nota: el transport SSE se puede habilitar montando el `FastMCP.sse_app()` en otra ruta si se requiere compatibilidad completa.

## ğŸ“ˆ Monitoreo

```bash
# Ver logs
docker logs -f invoice-platform

# EstadÃ­sticas
curl http://localhost:7000/api/assistant/stats

# Estado del servicio
docker ps
```

## ğŸ› Troubleshooting

### El servicio no inicia
```bash
# Ver logs
docker logs invoice-platform

# Verificar salud
curl http://localhost:7000/api/health
```

### Error de API Key
- Solo aplica si configuraste `LLM_API_BASE` hacia un proveedor remoto (Groq).
- Verifica que `LLM_API_KEY` estÃ© definido en `configs/env/.env`.
- Prueba la key directamente contra el dashboard del proveedor (p.ej. https://console.groq.com/).

### â±ï¸ Error "LÃ­mite de peticiones alcanzado"
**Causa**: El proveedor remoto (Groq u OpenAI-compatible) aplicÃ³ rate limiting

**SoluciÃ³n**:
- â¸ï¸ Espera 1-2 minutos entre peticiones
- ğŸ’¡ El sistema hace **4 reintentos automÃ¡ticos** con backoff exponencial
- ğŸ“Š LÃ­mites tÃ­picos: ~30 peticiones por minuto
- ğŸ’¾ Las facturas ya procesadas se cachean automÃ¡ticamente (no consumen API)

**Tips para evitar lÃ­mites**:
1. No subas muchas facturas seguidas
2. Espera unos segundos entre cada carga
3. Las facturas duplicadas no consumen API (cache por hash)

### Base de datos vacÃ­a
- Procesa facturas primero con el Pipeline tab
- Verifica que exista `/app/data/app.db`

### Factura con poco texto legible
- AsegÃºrate que la imagen/PDF tenga buena calidad
- El OCR requiere texto claro y legible
- PDFs nativos funcionan mejor que imÃ¡genes escaneadas

## ğŸ§¹ Mantenimiento

```bash
# Detener servicio
docker compose down

# Limpiar todo (incluye datos)
docker compose down -v

# Reiniciar
docker compose restart

# Ver uso de recursos
docker stats invoice-platform
```

## ğŸ“– DocumentaciÃ³n API Interactiva

Accede a Swagger UI:
```
http://localhost:7000/docs
```

Accede a ReDoc:
```
http://localhost:7000/redoc
```

## ğŸ¯ Roadmap

- [ ] Soporte para mÃ¡s formatos (Excel, CSV)
- [ ] API de webhooks para procesamiento asÃ­ncrono
- [ ] Dashboard de analytics
- [ ] Multi-tenancy
- [ ] Export a PDF/Excel
- [ ] IntegraciÃ³n con sistemas ERP

## ğŸ¤ ContribuciÃ³n

Este proyecto sigue una arquitectura modular. Para contribuir:

1. Los endpoints van en `src/routers/`
2. La lÃ³gica de negocio en `src/modules/`
3. El frontend en `src/static/`
4. Las configuraciones en `configs/env/`

## ğŸ“ Licencia

MIT License

## ğŸ™‹ Soporte

Para reportar bugs o solicitar features:
- Issues: GitHub Issues
- Docs: `/docs` endpoint
- Logs: `docker logs invoice-platform`

---

**Desarrollado con â¤ï¸ usando FastAPI, Groq, Tesseract y MCP**
